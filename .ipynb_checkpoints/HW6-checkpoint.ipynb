{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6 (20')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Please submit your assignment as an HTML or PDF file.\n",
    "\n",
    "Print your name (First and Last) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suhas Das\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here:\n",
    "print(\"Suhas Das\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Import the `pandas`, `matplotlib.pyplot`, `numpy`, `scipy` libraries and assign them with proper nicknames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here:\n",
    "import numpy as np\n",
    "import scipy \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete this code section.\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a function that output marginal summary statistics and missing values for continuous variable (10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`** (6')\n",
    "- Given a vector of continuous measure, you are asked to write a function named `fn_marginal_continuous`.\n",
    "- The function has one parameter `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our first case, we will assume the `input_vec` is an numpy array with missing values marked with `np.nan`.\n",
    "- The list of summary measure can be either **(mean, std)** or **(median, q1, q3)** depending on the normality assumption.\n",
    "    - To determine the normality assumption, you can rely on the p-value of the Shapiro-Wilk test.\n",
    "    - Relevant functions can be found here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html \n",
    "    - If the p-value < 0.05, it is not normally distributed, otherwise, you can treat it as normally distributed.\n",
    "    - Think about what measure to report based on the normality assumption.\n",
    "    - Part of relevant functions can be found here: https://numpy.org/doc/2.0/reference/generated/numpy.nanmean.html\n",
    "- The return statement should include two components: `missing_num` and `output_ls` (your summmary measure).\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and summary values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your summary values such that they have no more than **3** digits after the decimals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your defined function in this code chunk only.\n",
    "def fn_marginal_continuous(input_vec):\n",
    "    missing_num = int(np.sum(np.isnan(input_vec)))\n",
    "    clean_vec = input_vec[~np.isnan(input_vec)]\n",
    "\n",
    "    shapiro_test = scipy.stats.shapiro(clean_vec)\n",
    "    p_value = shapiro_test.pvalue\n",
    "\n",
    "    if p_value >= 0.05:\n",
    "        mean_val = float(np.round(np.mean(clean_vec), 3))\n",
    "        std_val = float(np.round(np.std(clean_vec), 3))\n",
    "        output_ls = [mean_val, std_val]\n",
    "    else:\n",
    "        median_val = float(np.round(np.median(clean_vec), 3))\n",
    "        q1 = float(np.round(np.percentile(clean_vec, 25), 3))\n",
    "        q3 = float(np.round(np.percentile(clean_vec, 75), 3))\n",
    "        output_ls = [median_val, q1, q3]\n",
    "        \n",
    "    return missing_num, output_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test your function with the following different arguments:** (4') <br>\n",
    "For each scenario, please export the results as `missing_num_x`, `output_ls_x` and print them out separately.\n",
    "1. A standard normal random vector with a sample size of 100, named `input_vec_1`.\n",
    "2. A Chi-squared random vector with a degree of freedom 1 and a sample size of 100, named `input_vec_2`.\n",
    "3. Change the first element of `input_vec_1` as `np.nan` and create a new array named `input_vec_3`.\n",
    "    - Note that to create a copy of an numpy array, use `np.copy()` first.\n",
    "4. Change the last element of `input_vec_2` as `np.nan` and create a new array named `input_vec_4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [0.111, 1.02])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your own code for scenario 1:\n",
    "input_vec_1 = np.random.normal(0,1,100)\n",
    "fn_marginal_continuous(input_vec_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [0.232, 0.031, 0.811])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your own code for scenario 2:\n",
    "input_vec_2 = np.random.chisquare(1,100)\n",
    "fn_marginal_continuous(input_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, [0.121, 1.02])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your own code for scenario 3:\n",
    "input_vec_3 = np.copy(input_vec_1)\n",
    "input_vec_3[0] = np.nan \n",
    "\n",
    "fn_marginal_continuous(input_vec_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, [0.232, 0.031, 0.744])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your own code for scenario 4:\n",
    "input_vec_4 = np.copy(input_vec_2) \n",
    "input_vec_4[-1] = np.nan \n",
    "\n",
    "fn_marginal_continuous(input_vec_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a function that output marginal summary statistics and missing values for categorical variable (5')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`**\n",
    "- Given a column vector, you are asked to write a function named `fn_marginal_categorical`.\n",
    "- The function has one parameter named `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our second case, we will assume the `input_vec` is a column from a pandas DataFrame with missing values marked with `np.nan`.\n",
    "    - You can use both functions to identify missing values and yield the number of missingness.\n",
    "    - Use `pd.Series.value_counts()` function to obtain the frequency and proportion of `input_vec`, denoted as `tab_count` and `tab_percent`, respectively.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "    - For proportion, please use percentage (0-100%). You can ignore % when reporting.\n",
    "- The return statement should include two components: `missing_num` and `output_tab` (your summmary measure).\n",
    "    - For your `output_tab`, combine the count and proportion together using `pd.concat()`. Your `output_tab` should have three columns: variable name, count, and proportion.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and percentgae values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your relevant summary values such that they have no more than **2** digits after the decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your defined function in this code chunk only.\n",
    "def fn_marginal_categorical(input_vec):\n",
    "    missing_num = int(pd.isna(input_vec).sum())\n",
    "\n",
    "    tab_count = input_vec.value_counts(dropna = True)\n",
    "    tab_percent = input_vec.value_counts(normalize = True, dropna = True) * 100 \n",
    "\n",
    "    output_tab = pd.concat([tab_count,tab_percent], axis=1).reset_index()\n",
    "    output_tab.columns = ['var name','count','prop']\n",
    "    \n",
    "    return missing_num, output_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test your written functions with a real dataset. (3')\n",
    "\n",
    "<font size='4'>\n",
    "    \n",
    "**Test the summary function for the continuous measure** (1')\n",
    "- Load the `PTSD dataset.xlsx` and name it as `ptsd_df`.\n",
    "    - The dataset should be stored under `data` folder when you sync changes and fetch origins the GitHub repository.\n",
    "- Use the column `pcl5month_score.baseline` as the input vector. This is a continuous measure.\n",
    "- Extract the corresponding column and give it a name `pcl5month_base`.\n",
    "- (*Optional*) You convert from a pandas.dataframe to an numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ptsd dataset in this code section only (no point for this part as you have done it a few times)\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "ptsd_df = pd.read_excel(\"{}/data/PTSD dataset.xlsx\".format(current_dir), sheet_name=\"main_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,\n",
       "     var name  count      prop\n",
       " 0       59.0     21  4.430380\n",
       " 1       46.0     19  4.008439\n",
       " 2       58.0     19  4.008439\n",
       " 3       50.0     18  3.797468\n",
       " 4       45.0     14  2.953586\n",
       " ..       ...    ...       ...\n",
       " 63      13.0      1  0.210970\n",
       " 64      18.0      1  0.210970\n",
       " 65       7.0      1  0.210970\n",
       " 66      77.0      1  0.210970\n",
       " 67      17.0      1  0.210970\n",
       " \n",
       " [68 rows x 3 columns])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test continuous measure\n",
    "pcl5month_base = ptsd_df[\"pcl5month_score.baseline\"]\n",
    "fn_marginal_categorical(pcl5month_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test the summary function for the categorical measure** (2')\n",
    "\n",
    "- Use the column `mdd_code` as the input vector. This is a binary vector.\n",
    "1. Extract the corresponding column and give it a name `mdd_code_vec`. Output your results as `missing_num_1` and `tab_1`. Print each element out (You will write `print()` twice).\n",
    "2. Create a copy of `mdd_code_vec` and name it as `mdd_code_vec_2`. Change its first element to `NaN`.\n",
    "    - Rerun the `fn_marginal_categorical()` with the new vector. Output your results as `missing_num_2` and `tab_2`. Print each element out (You will write `print()` twice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "   var name  count       prop\n",
      "0         0    340  70.393375\n",
      "1         1    143  29.606625\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 1 only:\n",
    "mdd_code_vec = ptsd_df[\"mdd_code\"]\n",
    "missing_num_1, tab_1 = fn_marginal_categorical(mdd_code_vec) \n",
    "print(missing_num_1) \n",
    "print(tab_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "   var name  count      prop\n",
      "0       0.0    339  70.33195\n",
      "1       1.0    143  29.66805\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 2 only:\n",
    "mdd_code_vec2 = mdd_code_vec.copy()\n",
    "mdd_code_vec2[0] = np.nan\n",
    "\n",
    "missing_num_2, tab_2 = fn_marginal_categorical(mdd_code_vec2) \n",
    "print(missing_num_2) \n",
    "print(tab_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lambda functions and for loop (2')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "- Create a ``` lambda ``` function that checks if column `pcl5_score_intake` is greater than 30, denoted as `fn_pcl5_ptsd_check`.\n",
    "- Create a new list `pcl5_score_intake_ls` that shows `True` if `pcl5_score_intake`>30 and `False` otherwise using a for loop.\n",
    "    - You can also try `map()` function to iterate the function over `pcl5_score_intake`.\n",
    "    - Syntax is simple: `map(function_name, iterable, ...)`. \n",
    "- Print out the number of patients with `pcl5_score_intake` over 30 and mark them as **Clinically Significant for PTSD**.\n",
    "    - Your output can be something like `XXX out of YYY patients (ZZZ%) were marked as clinically significant for PTSD.`\n",
    "    - Round your percentage with no more than **2** decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 out of 483 patients (93.37%) were marked as clinically significant for PTSD.\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "fn_pcl5_ptsd_check = lambda x: x > 30\n",
    "\n",
    "pcl5_score_intake_ls = list(map(fn_pcl5_ptsd_check, ptsd_df[\"pcl5_score_intake\"]))\n",
    "\n",
    "num_clinical = sum(pcl5_score_intake_ls)\n",
    "total_patients = len(pcl5_score_intake_ls)\n",
    "\n",
    "percent_clinical = round(num_clinical / total_patients * 100, 2)\n",
    "\n",
    "print(f\"{num_clinical} out of {total_patients} patients ({percent_clinical}%) were marked as clinically significant for PTSD.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
